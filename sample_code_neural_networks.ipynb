{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Data\n",
    "\n",
    "MNIST Data Introduction : https://www.tensorflow.org/versions/r0.12/tutorials/mnist/beginners/index.html#mnist-for-ml-beginners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "# black and white images with values in [0.0, 1.0]\n",
    "mnist.test.images[0][300:350]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network Example : Autoencoder\n",
    "\n",
    "Deep Auto-encoder Introduction : http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/auto%20(v7).pdf\n",
    "\n",
    "Reference : https://github.com/aymericdamien/TensorFlow-Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building the encoder\n",
    "def encoder(x, scope, n_input, n_hidden, n_code, n_layer):\n",
    "    # Using \"scope\" for variable-sharing (getting the same variable everytime)\n",
    "    with tf.variable_scope(scope):\n",
    "        # Input layer\n",
    "        W = tf.get_variable(\"W_in\", [n_input, n_hidden])\n",
    "        b = tf.get_variable(\"b_in\", [n_hidden])\n",
    "        layer_i = tf.nn.tanh(tf.add(tf.matmul(x, W), b))\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(n_layer - 1):\n",
    "            W = tf.get_variable(\"W_en_%d\" % i, [n_hidden, n_hidden])\n",
    "            b = tf.get_variable(\"b_en_%d\" % i, [n_hidden])\n",
    "            # activation function - tanh (Could be others)\n",
    "            layer_i = tf.nn.tanh(tf.add(tf.matmul(layer_i, W), b))\n",
    "\n",
    "        # Bottleneck layer (code)\n",
    "        W = tf.get_variable(\"W_encode\", [n_hidden, n_code])\n",
    "        b = tf.get_variable(\"b_encode\", [n_code])\n",
    "        # activation function - linear (could be relu, tanh or others)\n",
    "        code = tf.add(tf.matmul(layer_i, W), b)\n",
    "\n",
    "    return code\n",
    "\n",
    "\n",
    "# Building the decoder\n",
    "def decoder(code, scope, n_output, n_hidden, n_code, n_layer):\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        # Bottleneck layer input\n",
    "        W = tf.get_variable(\"W_decode\", [n_code, n_hidden])\n",
    "        b = tf.get_variable(\"b_decode\", [n_hidden])\n",
    "        # activation function - tanh (Could be others)\n",
    "        layer_i = tf.nn.tanh(tf.add(tf.matmul(code, W), b))\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(n_layer - 1):\n",
    "            W = tf.get_variable(\"W_de_%d\" % i, [n_hidden, n_hidden])\n",
    "            b = tf.get_variable(\"b_de_%d\" % i, [n_hidden])\n",
    "            # activation function - tanh (Could be others)\n",
    "            layer_i = tf.nn.tanh(tf.add(tf.matmul(layer_i, W), b))\n",
    "\n",
    "        # Output layer\n",
    "        W = tf.get_variable(\"W_out\", [n_hidden, n_output])\n",
    "        b = tf.get_variable(\"b_out\", [n_output])\n",
    "        # activation function - sigmoid\n",
    "        # (Since original data are values in [0.0, 1.0])\n",
    "        output = tf.nn.sigmoid(tf.add(tf.matmul(layer_i, W), b))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 30\n",
    "batch_size = 256\n",
    "display_step = 3\n",
    "examples_to_show = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden = 32\n",
    "n_code = 2  # code dimension\n",
    "n_layer = 3\n",
    "# MNIST data input (img shape: 28*28)\n",
    "n_input = 784\n",
    "\n",
    "# tf Graph input (only pictures)\n",
    "X = tf.placeholder(\"float\", [None, n_input])  # None - dynamic size\n",
    "\n",
    "# Construct the auto-encoder\n",
    "with tf.variable_scope(\"autoencoder\") as scope:\n",
    "    # encoder - input images, output codes\n",
    "    encoder_op = encoder(X, scope, n_input, n_hidden, n_code, n_layer)\n",
    "    # decoder - input codes, output decoded images\n",
    "    decoder_op = decoder(encoder_op, scope, n_input, n_hidden, n_code, n_layer)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = decoder_op\n",
    "    # Targets (Labels) are the input data.\n",
    "    y_true = X\n",
    "\n",
    "    # Define loss and optimizer, minimize the squared error\n",
    "    cost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "    # using RMSProp optimization technique\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the auto-encoder\n",
    "with tf.variable_scope(\"autoencoder\", reuse=True) as scope:  # set the scope to reuse variables!\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    with sess.as_default():\n",
    "        sess.run(init)\n",
    "\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        # Training cycle\n",
    "        for epoch in range(training_epochs):\n",
    "\n",
    "            # Loop over all batches\n",
    "            for i in range(total_batch):\n",
    "                batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "                # Run optimization op (backprop) and cost op (to get loss value)\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})\n",
    "\n",
    "            # Display logs per epoch step\n",
    "            if epoch % display_step == 0:\n",
    "                print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        # Applying encode and decode over test set\n",
    "        encode_decode = sess.run(y_pred, feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "\n",
    "        # Visualize and compare original images with their reconstructions\n",
    "        f, a = plt.subplots(2, 10, figsize=(10, 2))\n",
    "        for i in range(examples_to_show):\n",
    "            a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "            a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))\n",
    "\n",
    "        f.show()\n",
    "        plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute all the codes of training images\n",
    "with tf.variable_scope(\"autoencoder\", reuse=True) as scope:\n",
    "\n",
    "    with sess.as_default():\n",
    "        codes = sess.run(encoder_op, feed_dict={X: mnist.train.images})\n",
    "\n",
    "# Visualize auto-encoder codes\n",
    "color = np.array(['#fb9a99', '#e31a1c', '#ff7f00', '#fdbf6f', '#b2df8a', '#33a02c',\n",
    "                  '#a6cee3', '#1f78b4', '#cab2d6', '#6a3d9a'])\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(codes[:, 0], codes[:, 1], s=4, alpha=0.5, color=color[np.argmax(mnist.train.labels, axis=1)])\n",
    "plt.xlim([-15, 15])\n",
    "plt.ylim([-15, 15])\n",
    "# plt.savefig('auto_train.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute all the codes of testing images\n",
    "with tf.variable_scope(\"autoencoder\", reuse=True) as scope:\n",
    "\n",
    "    with sess.as_default():\n",
    "        codes = sess.run(encoder_op, feed_dict={X: mnist.test.images})\n",
    "\n",
    "# Visualize auto-encoder codes\n",
    "color = np.array(['#fb9a99', '#e31a1c', '#ff7f00', '#fdbf6f', '#b2df8a', '#33a02c',\n",
    "                  '#a6cee3', '#1f78b4', '#cab2d6', '#6a3d9a'])\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(codes[:, 0], codes[:, 1], s=4, alpha=0.5, color=color[np.argmax(mnist.test.labels, axis=1)])\n",
    "plt.xlim([-15, 15])\n",
    "plt.ylim([-15, 15])\n",
    "# plt.savefig('auto_test.png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network\n",
    "\n",
    "Introduction to Neural Network with Memory : http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/RNN%20(v4).pdf\n",
    "\n",
    "Reference : https://github.com/aymericdamien/TensorFlow-Examples\n",
    "\n",
    "Example for MNIST:\n",
    "\n",
    "- Break the 28 * 28 image into a sequence of 28 vectors (each row is a vector)\n",
    "- Feed RNN a sequence of rows of one image and predict the digit (0 - 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct a Recurrent Neural Network - support minibatch\n",
    "def RNN(x, n_input, n_hidden, n_classes, n_steps, scope=None):\n",
    "\n",
    "    with tf.variable_scope(scope or \"RNN\"):\n",
    "        # x:[batchsize, n_steps, n_input]; Permuting batch_size and n_steps\n",
    "        x = tf.transpose(x, [1, 0, 2])\n",
    "        # Reshape to (n_steps*batch_size, n_input)\n",
    "        x = tf.reshape(x, [-1, n_input])\n",
    "        # Split: list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "        x = tf.split(0, n_steps, x)\n",
    "\n",
    "        outputs = []\n",
    "        memory = tf.get_variable(\"memory\", [1, n_hidden])\n",
    "        for i in range(len(x)):\n",
    "            W_o = tf.get_variable(\"W_out\", [n_hidden, n_classes])\n",
    "            W_h = tf.get_variable(\"W_mem\", [n_hidden, n_hidden])\n",
    "            W_i = tf.get_variable(\"W_in\", [n_input, n_hidden])\n",
    "\n",
    "            # memory passed from last step\n",
    "            memory_read = tf.matmul(memory, W_h)\n",
    "\n",
    "            # update memory - using \"tanh\" activation function\n",
    "            memory = tf.nn.tanh(tf.add(tf.matmul(x[i], W_i), memory_read))\n",
    "\n",
    "            # output : a sequence\n",
    "            outputs.append(tf.matmul(memory, W_o))\n",
    "\n",
    "            # set the variables to be shared !\n",
    "            if i == 0:\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "    return outputs[-1]  # only need the last output to predict the digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.003\n",
    "training_iters = 100000\n",
    "batch_size = 256\n",
    "display_step = 50\n",
    "\n",
    "# Network Parameters\n",
    "nn_input = 28  # MNIST data input (img shape: 28*28)\n",
    "nn_steps = 28  # 28 rows\n",
    "nn_hidden = 128  # hidden layer : num of neurons\n",
    "nn_classes = 10  # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, nn_steps, nn_input])\n",
    "y = tf.placeholder(\"float\", [None, nn_classes])\n",
    "\n",
    "# Construct RNN\n",
    "with tf.variable_scope(\"RNN_run\") as scope:\n",
    "    pred = RNN(x, nn_input, nn_hidden, nn_classes, nn_steps, scope)\n",
    "\n",
    "    # Define loss and optimizer - apply \"softmax\" on pred and compute the cross entropy\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "\n",
    "    # using the Adam optimization technique\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # Evaluate model\n",
    "    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the RNN and evalute results\n",
    "with tf.variable_scope(\"RNN_run\", reuse=True) as scope:\n",
    "\n",
    "    sess = tf.Session()\n",
    "    with sess.as_default():\n",
    "        sess.run(init)\n",
    "        step = 1\n",
    "\n",
    "        # Keep training until reach max iterations\n",
    "        while step * batch_size < training_iters:\n",
    "            # get minibatch data\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "            # Reshape data to get 28 seq of 28 elements\n",
    "            batch_x = batch_x.reshape((batch_size, nn_steps, nn_input))\n",
    "\n",
    "            # Run optimization op (backprop) - training\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "            if step % display_step == 0 or step == 1:\n",
    "                # Calculate batch accuracy\n",
    "                acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "                # Calculate batch loss\n",
    "                loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "                print(\"Iter \" + str(step*batch_size) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        # Calculate accuracy for 128 mnist test images\n",
    "        test_len = 128\n",
    "        test_data = mnist.test.images[:test_len].reshape((-1, nn_steps, nn_input))\n",
    "        test_label = mnist.test.labels[:test_len]\n",
    "        print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_data, y: test_label}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network with Attention\n",
    "\n",
    "Introduction to Attention Interface : http://distill.pub/2016/augmented-rnns/#attentional-interfaces\n",
    "\n",
    "Introduction to Attention-based model : http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/Attain%20(v3).pdf\n",
    "\n",
    "Example for MNIST :\n",
    "\n",
    "- Break the 28 * 28 image into a sequence of 28 vectors (each row is a vector)\n",
    "- Feed RNN with attention a sequence of rows of one image and predict the digit (0 - 9)\n",
    "\n",
    "( however, since the attention mechanism is more suitable for sequence-to-sequence tasks, <br>\n",
    " training on MNIST seems not showing the advantage of the attention mechanism. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recurrent Neural Network with Attention\n",
    "def RNN_attention(x, n_input, n_hidden, n_attn_hidden, n_classes, scope=None):\n",
    "\n",
    "    with tf.variable_scope(scope or \"RNN\"):\n",
    "\n",
    "        # initialize variables for \"attention match function\" - a small DNN\n",
    "        W_in = tf.get_variable(\"Win_atten\", [n_input + n_hidden, n_attn_hidden])\n",
    "        b_in = tf.get_variable(\"bin_atten\", [n_attn_hidden])\n",
    "        W2 = tf.get_variable(\"W2_atten\", [n_attn_hidden, n_attn_hidden])\n",
    "        b2 = tf.get_variable(\"b2_atten\", [n_attn_hidden])\n",
    "        W_out = tf.get_variable(\"Wout_atten\", [n_attn_hidden, 1])\n",
    "        b_out = tf.get_variable(\"bout_atten\", [1])\n",
    "\n",
    "        # initialize variables for RNN\n",
    "        W_h = tf.get_variable(\"W_mem\", [n_hidden, n_hidden])\n",
    "        W_i = tf.get_variable(\"W_in\", [n_input, n_hidden])\n",
    "        b_i = tf.get_variable(\"b_in\", [n_hidden])\n",
    "        W_o = tf.get_variable(\"W_out\", [n_hidden, n_classes])\n",
    "        b_o = tf.get_variable(\"b_out\", [n_classes])\n",
    "        state = tf.get_variable(\"state0\", [n_hidden])\n",
    "\n",
    "        # attention mechaism - given a query, compute the attention scores across the input sequence\n",
    "        def attention(query, x, scope):\n",
    "\n",
    "            with tf.variable_scope(scope):\n",
    "                # variable sharing\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "                \n",
    "                W_in = tf.get_variable(\"Win_atten\")\n",
    "                b_in = tf.get_variable(\"bin_atten\")\n",
    "                W2 = tf.get_variable(\"W2_atten\")\n",
    "                b2 = tf.get_variable(\"b2_atten\")\n",
    "                W_out = tf.get_variable(\"Wout_atten\")\n",
    "                b_out = tf.get_variable(\"bout_atten\")\n",
    "\n",
    "                def match(_, batch_xi):\n",
    "                    # batch_xi : [batchsize, feature_dim]\n",
    "                    dnn_input = tf.concat(1, [batch_xi, query])\n",
    "\n",
    "                    # attention \"match\" DNN\n",
    "                    a_attn = tf.nn.relu(tf.add(tf.matmul(dnn_input, W_in), b_in))\n",
    "                    a_attn2 = tf.nn.relu(tf.add(tf.matmul(a_attn, W2), b2))\n",
    "                    # attention score at this step : [batchsize, 1]\n",
    "                    attn_score = tf.add(tf.matmul(a_attn2, W_out), b_out)\n",
    "\n",
    "                    return attn_score\n",
    "                \n",
    "                # concatenate the query with each of input features - to feed into the match function\n",
    "                attn_scores = tf.scan(match, tf.transpose(x, [1, 0, 2]), initializer=tf.matmul(x[0], tf.ones([n_input, 1])))\n",
    "\n",
    "                attn_scores = tf.transpose(attn_scores, [1, 2, 0])  # reshape to [batchsize, 1, n_seq]\n",
    "                attn = tf.nn.softmax(attn_scores)\n",
    "\n",
    "                return attn\n",
    "\n",
    "        # RNN cell\n",
    "        def cell(memory, _):\n",
    "            # variable sharing\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            W_h = tf.get_variable(\"W_mem\")\n",
    "            W_i = tf.get_variable(\"W_in\")\n",
    "            b_i = tf.get_variable(\"b_in\")\n",
    "\n",
    "            # memory passed from last step\n",
    "            mem = tf.matmul(memory, W_h)\n",
    "\n",
    "            # use last-step memory as query to compute attention scores\n",
    "            attn = attention(memory, x, scope)\n",
    "            # calculate the attended features as the RNN input\n",
    "            atten_x = tf.reshape(tf.batch_matmul(attn, x), [-1, n_input])\n",
    "\n",
    "            # update RNN memory with \"tanh\" activation\n",
    "            memory = tf.nn.tanh(tf.add(tf.add(tf.matmul(atten_x, W_i), b_i), mem))\n",
    "\n",
    "            return memory\n",
    "\n",
    "        # loop over the x sequence and calculate the output sequence\n",
    "        states = tf.scan(lambda state, _: state, x, initializer=state)\n",
    "        out_seq = tf.scan(cell, tf.transpose(x, [1, 0, 2]), initializer=states)\n",
    "        outputs = tf.nn.softmax(tf.add(tf.matmul(out_seq[-1], W_o), b_o))\n",
    "\n",
    "    return outputs  # only the last output to predict the digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.003\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "display_step = 5\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 28\n",
    "n_steps = 28\n",
    "n_hidden = 128  # hidden layer num of neurons\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "n_attn_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "with tf.variable_scope(\"RNN_attn_run\", reuse=True) as scope:\n",
    "    pred = RNN_attention(x, n_input, n_hidden, n_attn_hidden, n_classes, scope)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    gvs = optimizer.compute_gradients(cost)\n",
    "    capped_gvs = [(tf.clip_by_value(grad, -0.1, 0.1), var) for grad, var in gvs]\n",
    "    optimizer = optimizer.apply_gradients(capped_gvs)\n",
    "    \n",
    "    # Evaluate model\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the RNN and evalute results\n",
    "with tf.variable_scope(\"RNN_attn_run\", reuse=True) as scope:\n",
    "\n",
    "    sess = tf.Session()\n",
    "    with sess.as_default():\n",
    "        sess.run(init)\n",
    "        step = 1\n",
    "\n",
    "        # Keep training until reach max iterations\n",
    "        while step * batch_size < training_iters:\n",
    "            # get minibatch data\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "            # Reshape data to get 28 seq of 28 elements\n",
    "            batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "\n",
    "            # Run optimization op (backprop) - training\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "            if step % display_step == 0 or step == 1:\n",
    "                # Calculate batch accuracy\n",
    "                acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "                # Calculate batch loss\n",
    "                loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "                print(\"Iter \" + str(step*batch_size) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        # Calculate accuracy for 128 mnist test images\n",
    "        test_len = 128\n",
    "        test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "        test_label = mnist.test.labels[:test_len]\n",
    "        print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_data, y: test_label}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
